{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7e08c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import acquire\n",
    "import prepare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1793d85",
   "metadata": {},
   "source": [
    "## 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546bcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic = prepare.prep_titantic(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df608146",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'survived'\n",
    "train, validate, test = prepare.train_val_test(titanic, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8e96efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 623 entries, 748 to 136\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   survived                 623 non-null    int64  \n",
      " 1   pclass                   623 non-null    int64  \n",
      " 2   sex                      623 non-null    object \n",
      " 3   sibsp                    623 non-null    int64  \n",
      " 4   parch                    623 non-null    int64  \n",
      " 5   fare                     623 non-null    float64\n",
      " 6   embark_town              623 non-null    object \n",
      " 7   alone                    623 non-null    int64  \n",
      " 8   sex_male                 623 non-null    uint8  \n",
      " 9   embark_town_Queenstown   623 non-null    uint8  \n",
      " 10  embark_town_Southampton  623 non-null    uint8  \n",
      "dtypes: float64(1), int64(5), object(2), uint8(3)\n",
      "memory usage: 45.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8cc1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09d24b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2a86ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = y_train.mode()\n",
    "baseline_acc = (y_train == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5ba6d609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0\n",
      "Baseline accuracy: 61.64%\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline: 0')\n",
    "print(f'Baseline accuracy: {baseline_acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93b2f2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(max_depth = 10, min_samples_leaf = 1, random_state = seed)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59bfe378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bb01bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303cdc8",
   "metadata": {},
   "source": [
    "## 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0215e36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92776886035313"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5e6ded7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[367,  17],\n",
       "       [ 28, 211]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b1bc1f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       384\n",
      "           1       0.93      0.88      0.90       239\n",
      "\n",
      "    accuracy                           0.93       623\n",
      "   macro avg       0.93      0.92      0.92       623\n",
      "weighted avg       0.93      0.93      0.93       623\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>died</th>\n",
       "      <th>survived</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.929114</td>\n",
       "      <td>0.925439</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>0.927276</td>\n",
       "      <td>0.927704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>0.919287</td>\n",
       "      <td>0.927769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.942234</td>\n",
       "      <td>0.903640</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>0.922937</td>\n",
       "      <td>0.927428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>384.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 died    survived  accuracy   macro avg  weighted avg\n",
       "precision    0.929114    0.925439  0.927769    0.927276      0.927704\n",
       "recall       0.955729    0.882845  0.927769    0.919287      0.927769\n",
       "f1-score     0.942234    0.903640  0.927769    0.922937      0.927428\n",
       "support    384.000000  239.000000  0.927769  623.000000    623.000000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_train, train_preds))\n",
    "\n",
    "report = classification_report(y_train, train_preds, output_dict = True, target_names=('died','survived'))\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b875a",
   "metadata": {},
   "source": [
    "## 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10b5edb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 17, 28, 211, 623)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train,train_preds).ravel()\n",
    "acc_all = tn + tp + fn + fp\n",
    "\n",
    "tn, fp, fn, tp, acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f3d9553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.777%\n",
      "True Positive Rate: 88.285%\n",
      "False Positive Rate: 4.427%\n",
      "True Negative Rate: 95.573%\n",
      "False Negative Rate: 11.715%\n",
      "Precision: 92.544%\n",
      "Recall: 88.285%\n",
      "F1 Score: 90.364%\n",
      "Support (0): 239\n",
      "Support (1): 384\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn)/acc_all\n",
    "print(f\"Accuracy: {accuracy:.3%}\")\n",
    "\n",
    "true_positive_rate = tp/(tp+fn)\n",
    "print(f\"True Positive Rate: {true_positive_rate:.3%}\")\n",
    "\n",
    "false_positive_rate = fp/(fp+tn)\n",
    "print(f\"False Positive Rate: {false_positive_rate:.3%}\")\n",
    "\n",
    "true_negative_rate = tn/(tn+fp)\n",
    "print(f\"True Negative Rate: {true_negative_rate:.3%}\")\n",
    "\n",
    "false_negative_rate = fn/(fn+tp)\n",
    "print(f\"False Negative Rate: {false_negative_rate:.3%}\")\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "print(f\"Precision: {precision:.3%}\")\n",
    "\n",
    "recall = tp/(tp+fn)\n",
    "print(f\"Recall: {recall:.3%}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score:.3%}\")\n",
    "\n",
    "support_pos = tp + fn\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = fp + tn\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd847fd",
   "metadata": {},
   "source": [
    "## 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e6b168c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth 1\n",
      "Tree with min sample 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.812808    0.751152  0.791332    0.781980      0.789155\n",
      "recall       0.859375    0.682008  0.791332    0.770692      0.791332\n",
      "f1-score     0.835443    0.714912  0.791332    0.775178      0.789204\n",
      "support    384.000000  239.000000  0.791332  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 2\n",
      "Tree with min sample 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.812808    0.751152  0.791332    0.781980      0.789155\n",
      "recall       0.859375    0.682008  0.791332    0.770692      0.791332\n",
      "f1-score     0.835443    0.714912  0.791332    0.775178      0.789204\n",
      "support    384.000000  239.000000  0.791332  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 3\n",
      "Tree with min sample 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.782241    0.906667  0.812199    0.844454      0.829974\n",
      "recall       0.963542    0.569038  0.812199    0.766290      0.812199\n",
      "f1-score     0.863477    0.699229  0.812199    0.781353      0.800467\n",
      "support    384.000000  239.000000  0.812199  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 4\n",
      "Tree with min sample 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.805804    0.868571  0.823435    0.837187      0.829883\n",
      "recall       0.940104    0.635983  0.823435    0.788044      0.823435\n",
      "f1-score     0.867788    0.734300  0.823435    0.801044      0.816578\n",
      "support    384.000000  239.000000  0.823435  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 5\n",
      "Tree with min sample 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829384    0.830846  0.829856    0.830115      0.829945\n",
      "recall       0.911458    0.698745  0.829856    0.805102      0.829856\n",
      "f1-score     0.868486    0.759091  0.829856    0.813789      0.826519\n",
      "support    384.000000  239.000000  0.829856  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 6\n",
      "Tree with min sample 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.839243    0.855000  0.844302    0.847122      0.845288\n",
      "recall       0.924479    0.715481  0.844302    0.819980      0.844302\n",
      "f1-score     0.879802    0.779043  0.844302    0.829423      0.841148\n",
      "support    384.000000  239.000000  0.844302  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 7\n",
      "Tree with min sample 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.830275    0.882353  0.845907    0.856314      0.850254\n",
      "recall       0.942708    0.690377  0.845907    0.816542      0.845907\n",
      "f1-score     0.882927    0.774648  0.845907    0.828787      0.841388\n",
      "support    384.000000  239.000000  0.845907  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 8\n",
      "Tree with min sample 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.857143    0.857143  0.857143    0.857143      0.857143\n",
      "recall       0.921875    0.753138  0.857143    0.837507      0.857143\n",
      "f1-score     0.888331    0.801782  0.857143    0.845056      0.855128\n",
      "support    384.000000  239.000000  0.857143  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 9\n",
      "Tree with min sample 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.863309    0.883495  0.869984    0.873402      0.871053\n",
      "recall       0.937500    0.761506  0.869984    0.849503      0.869984\n",
      "f1-score     0.898876    0.817978  0.869984    0.858427      0.867841\n",
      "support    384.000000  239.000000  0.869984  623.000000    623.000000\n",
      "\n",
      "Tree with max depth 10\n",
      "Tree with min sample 1\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.848970    0.930108  0.873194    0.889539      0.880097\n",
      "recall       0.966146    0.723849  0.873194    0.844998      0.873194\n",
      "f1-score     0.903776    0.814118  0.873194    0.858947      0.869381\n",
      "support    384.000000  239.000000  0.873194  623.000000    623.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 11\n",
    "\n",
    "for i in range(1, 11):\n",
    "        \n",
    "    clf = DecisionTreeClassifier(max_depth = i, min_samples_leaf = j, random_state = 42)\n",
    "           \n",
    "    clf.fit(X_train, y_train)\n",
    "        \n",
    "    y_preds = clf.predict(X_train)\n",
    "        \n",
    "    report = classification_report(y_train, y_preds, output_dict = True)\n",
    "    \n",
    "    j -= 1   \n",
    "    \n",
    "    print(f'Tree with max depth {i}')\n",
    "    print(f'Tree with min sample {j}')\n",
    "    print(pd.DataFrame(report))\n",
    "    print()\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c7869",
   "metadata": {},
   "source": [
    "## 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2482333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    for j in range(10, 1, -1):\n",
    "    \n",
    "        rf = RandomForestClassifier(max_depth = i, min_samples_leaf = j, random_state = seed)\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        train_acc = rf.score(X_train, y_train)\n",
    "\n",
    "        val_acc = rf.score(X_validate, y_validate)\n",
    "\n",
    "        output = {\n",
    "                \"max_depth\": i,\n",
    "                'min_sample_leaf': j,\n",
    "                \"train_accuracy\": train_acc,\n",
    "                \"validate_accuracy\": val_acc\n",
    "                 }\n",
    "\n",
    "        metric.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b2f9d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth of 1.\n",
      "Min Sample leaf 10.\n",
      "Train accuracy: 75.76%.\n",
      "Validate accuracy: 76.21%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 2.\n",
      "Min Sample leaf 9.\n",
      "Train accuracy: 80.10%.\n",
      "Validate accuracy: 79.42%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 3.\n",
      "Min Sample leaf 8.\n",
      "Train accuracy: 81.54%.\n",
      "Validate accuracy: 80.39%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 4.\n",
      "Min Sample leaf 7.\n",
      "Train accuracy: 82.50%.\n",
      "Validate accuracy: 81.67%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 5.\n",
      "Min Sample leaf 6.\n",
      "Train accuracy: 82.99%.\n",
      "Validate accuracy: 82.32%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 6.\n",
      "Min Sample leaf 5.\n",
      "Train accuracy: 83.15%.\n",
      "Validate accuracy: 82.32%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 7.\n",
      "Min Sample leaf 4.\n",
      "Train accuracy: 85.55%.\n",
      "Validate accuracy: 85.21%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 8.\n",
      "Min Sample leaf 3.\n",
      "Train accuracy: 87.16%.\n",
      "Validate accuracy: 87.46%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 9.\n",
      "Min Sample leaf 2.\n",
      "Train accuracy: 88.76%.\n",
      "Validate accuracy: 88.42%\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Max depth of 10.\n",
      "Min Sample leaf 1.\n",
      "Train accuracy: 92.78%.\n",
      "Validate accuracy: 92.28%\n",
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 11 \n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    \n",
    "    j -= 1\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth = i, min_samples_leaf = j, random_state = seed)\n",
    "                                \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = rf.score(X_train, y_train)\n",
    "    \n",
    "    val_acc = rf.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "            \"max_depth\": i,\n",
    "            'min_sample_leaf': j,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"validate_accuracy\": val_acc\n",
    "             }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "    print(f'Max depth of {i}.\\nMin Sample leaf {j}.\\nTrain accuracy: {train_acc:.2%}.\\nValidate accuracy: {val_acc:.2%}')\n",
    "    print()\n",
    "    print('---------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845180d",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "\n",
    "  - Max depth of 10 with a min sample leaf of 1 gives us the best in our sample data, giving us a train accuracy of 92.78%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29065f24",
   "metadata": {},
   "source": [
    "## After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3744afa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.881029</td>\n",
       "      <td>-0.004624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869984</td>\n",
       "      <td>0.874598</td>\n",
       "      <td>-0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>-0.004588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.884430</td>\n",
       "      <td>0.887460</td>\n",
       "      <td>-0.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871589</td>\n",
       "      <td>0.874598</td>\n",
       "      <td>-0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>-0.002999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861958</td>\n",
       "      <td>0.864952</td>\n",
       "      <td>-0.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.839486</td>\n",
       "      <td>0.842444</td>\n",
       "      <td>-0.002957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895666</td>\n",
       "      <td>0.897106</td>\n",
       "      <td>-0.001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>-0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>-0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.887460</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.852327</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908507</td>\n",
       "      <td>0.906752</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869984</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.863563</td>\n",
       "      <td>0.861736</td>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.847512</td>\n",
       "      <td>0.845659</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.001884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.001889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922953</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855538</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.003489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>0.922830</td>\n",
       "      <td>0.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869984</td>\n",
       "      <td>0.864952</td>\n",
       "      <td>0.005032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850722</td>\n",
       "      <td>0.845659</td>\n",
       "      <td>0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.005104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.005104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.845907</td>\n",
       "      <td>0.839228</td>\n",
       "      <td>0.006679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.839486</td>\n",
       "      <td>0.832797</td>\n",
       "      <td>0.006689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.836276</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.006694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.836276</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.006694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833066</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.006699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.006704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.006715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.006715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.837881</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.008315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.008315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.008315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.008320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.008320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.008325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.802568</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.008356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.009925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.009925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.009930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.009930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.009930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841091</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.011509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.837881</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.011515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.011530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.011535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805778</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.011566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.810289</td>\n",
       "      <td>0.013146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.813804</td>\n",
       "      <td>0.800643</td>\n",
       "      <td>0.013161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.817014</td>\n",
       "      <td>0.800643</td>\n",
       "      <td>0.016371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.817014</td>\n",
       "      <td>0.800643</td>\n",
       "      <td>0.016371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813804</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.016377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_sample_leaf  train_accuracy  validate_accuracy  difference\n",
       "12          7                2        0.876404           0.881029   -0.004624\n",
       "18         10                3        0.869984           0.874598   -0.004614\n",
       "13          6                2        0.853933           0.858521   -0.004588\n",
       "11          8                2        0.884430           0.887460   -0.003030\n",
       "20          8                3        0.871589           0.874598   -0.003009\n",
       "27         10                4        0.865169           0.868167   -0.002999\n",
       "4           6                1        0.861958           0.864952   -0.002994\n",
       "22          6                3        0.839486           0.842444   -0.002957\n",
       "3           7                1        0.895666           0.897106   -0.001440\n",
       "29          8                4        0.857143           0.858521   -0.001378\n",
       "87          4               10        0.821830           0.823151   -0.001321\n",
       "9          10                2        0.887640           0.887460    0.000181\n",
       "36         10                5        0.852327           0.852090    0.000237\n",
       "2           8                1        0.908507           0.906752    0.001755\n",
       "21          7                3        0.869984           0.868167    0.001817\n",
       "28          9                4        0.863563           0.861736    0.001827\n",
       "39          7                5        0.847512           0.845659    0.001853\n",
       "15          4                2        0.828250           0.826367    0.001884\n",
       "57          7                7        0.825040           0.823151    0.001889\n",
       "1           9                1        0.922953           0.919614    0.003339\n",
       "10          9                2        0.887640           0.884244    0.003396\n",
       "30          7                4        0.855538           0.852090    0.003448\n",
       "42          4                5        0.829856           0.826367    0.003489\n",
       "81         10               10        0.826645           0.823151    0.003494\n",
       "78          4                9        0.826645           0.823151    0.003494\n",
       "63         10                8        0.826645           0.823151    0.003494\n",
       "75          7                9        0.826645           0.823151    0.003494\n",
       "0          10                1        0.927769           0.922830    0.004939\n",
       "19          9                3        0.869984           0.864952    0.005032\n",
       "37          9                5        0.850722           0.845659    0.005063\n",
       "6           4                1        0.828250           0.823151    0.005099\n",
       "49          6                6        0.828250           0.823151    0.005099\n",
       "72         10                9        0.828250           0.823151    0.005099\n",
       "64          9                8        0.828250           0.823151    0.005099\n",
       "33          4                4        0.828250           0.823151    0.005099\n",
       "41          5                5        0.828250           0.823151    0.005099\n",
       "82          9               10        0.828250           0.823151    0.005099\n",
       "73          9                9        0.825040           0.819936    0.005104\n",
       "83          8               10        0.825040           0.819936    0.005104\n",
       "38          8                5        0.845907           0.839228    0.006679\n",
       "47          8                6        0.839486           0.832797    0.006689\n",
       "45         10                6        0.836276           0.829582    0.006694\n",
       "46          9                6        0.836276           0.829582    0.006694\n",
       "23          5                3        0.833066           0.826367    0.006699\n",
       "50          5                6        0.829856           0.823151    0.006704\n",
       "56          8                7        0.826645           0.819936    0.006710\n",
       "51          4                6        0.826645           0.819936    0.006710\n",
       "66          7                8        0.826645           0.819936    0.006710\n",
       "54         10                7        0.826645           0.819936    0.006710\n",
       "69          4                8        0.823435           0.816720    0.006715\n",
       "76          6                9        0.823435           0.816720    0.006715\n",
       "71          2                8        0.800963           0.794212    0.006751\n",
       "62          2                7        0.800963           0.794212    0.006751\n",
       "80          2                9        0.800963           0.794212    0.006751\n",
       "89          2               10        0.800963           0.794212    0.006751\n",
       "14          5                2        0.837881           0.829582    0.008299\n",
       "40          6                5        0.831461           0.823151    0.008310\n",
       "32          5                4        0.831461           0.823151    0.008310\n",
       "48          7                6        0.828250           0.819936    0.008315\n",
       "58          6                7        0.828250           0.819936    0.008315\n",
       "24          4                3        0.828250           0.819936    0.008315\n",
       "74          8                9        0.825040           0.816720    0.008320\n",
       "60          4                7        0.825040           0.816720    0.008320\n",
       "86          5               10        0.821830           0.813505    0.008325\n",
       "53          2                6        0.802568           0.794212    0.008356\n",
       "65          8                8        0.826645           0.816720    0.009925\n",
       "55          9                7        0.826645           0.816720    0.009925\n",
       "68          5                8        0.823435           0.813505    0.009930\n",
       "77          5                9        0.823435           0.813505    0.009930\n",
       "84          7               10        0.823435           0.813505    0.009930\n",
       "8           2                1        0.807384           0.797428    0.009956\n",
       "26          2                3        0.807384           0.797428    0.009956\n",
       "35          2                4        0.807384           0.797428    0.009956\n",
       "17          2                2        0.807384           0.797428    0.009956\n",
       "5           5                1        0.841091           0.829582    0.011509\n",
       "31          6                4        0.837881           0.826367    0.011515\n",
       "59          5                7        0.828250           0.816720    0.011530\n",
       "85          6               10        0.825040           0.813505    0.011535\n",
       "70          3                8        0.815409           0.803859    0.011551\n",
       "79          3                9        0.815409           0.803859    0.011551\n",
       "88          3               10        0.815409           0.803859    0.011551\n",
       "61          3                7        0.815409           0.803859    0.011551\n",
       "44          2                5        0.805778           0.794212    0.011566\n",
       "67          6                8        0.823435           0.810289    0.013146\n",
       "52          3                6        0.813804           0.800643    0.013161\n",
       "16          3                2        0.818620           0.803859    0.014761\n",
       "7           3                1        0.818620           0.803859    0.014761\n",
       "34          3                4        0.817014           0.800643    0.016371\n",
       "25          3                3        0.817014           0.800643    0.016371\n",
       "43          3                5        0.813804           0.797428    0.016377"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df = pd.DataFrame(metric)\n",
    "models_df\n",
    "models_df['difference'] = models_df['train_accuracy'] - models_df['validate_accuracy'] \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "models_df.sort_values('difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c5c61a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813804</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.016377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.817014</td>\n",
       "      <td>0.800643</td>\n",
       "      <td>0.016371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.817014</td>\n",
       "      <td>0.800643</td>\n",
       "      <td>0.016371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.813804</td>\n",
       "      <td>0.800643</td>\n",
       "      <td>0.013161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.810289</td>\n",
       "      <td>0.013146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805778</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.011566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.011535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.011530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.837881</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.011515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841091</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.011509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.009930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.009930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.009930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.009925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.009925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.802568</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.008356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.008325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.008320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.008320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.008315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.008315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.008315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.837881</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.006715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.006715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.006704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833066</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.006699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.836276</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.006694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.836276</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.006694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.839486</td>\n",
       "      <td>0.832797</td>\n",
       "      <td>0.006689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.845907</td>\n",
       "      <td>0.839228</td>\n",
       "      <td>0.006679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.005104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.005104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850722</td>\n",
       "      <td>0.845659</td>\n",
       "      <td>0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869984</td>\n",
       "      <td>0.864952</td>\n",
       "      <td>0.005032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>0.922830</td>\n",
       "      <td>0.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.003489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855538</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922953</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.001889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.001884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.847512</td>\n",
       "      <td>0.845659</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.863563</td>\n",
       "      <td>0.861736</td>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869984</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908507</td>\n",
       "      <td>0.906752</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.852327</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.887460</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>-0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>-0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895666</td>\n",
       "      <td>0.897106</td>\n",
       "      <td>-0.001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.839486</td>\n",
       "      <td>0.842444</td>\n",
       "      <td>-0.002957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861958</td>\n",
       "      <td>0.864952</td>\n",
       "      <td>-0.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>-0.002999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871589</td>\n",
       "      <td>0.874598</td>\n",
       "      <td>-0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.884430</td>\n",
       "      <td>0.887460</td>\n",
       "      <td>-0.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>-0.004588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869984</td>\n",
       "      <td>0.874598</td>\n",
       "      <td>-0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.881029</td>\n",
       "      <td>-0.004624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_sample_leaf  train_accuracy  validate_accuracy  difference\n",
       "43          3                5        0.813804           0.797428    0.016377\n",
       "34          3                4        0.817014           0.800643    0.016371\n",
       "25          3                3        0.817014           0.800643    0.016371\n",
       "7           3                1        0.818620           0.803859    0.014761\n",
       "16          3                2        0.818620           0.803859    0.014761\n",
       "52          3                6        0.813804           0.800643    0.013161\n",
       "67          6                8        0.823435           0.810289    0.013146\n",
       "44          2                5        0.805778           0.794212    0.011566\n",
       "70          3                8        0.815409           0.803859    0.011551\n",
       "79          3                9        0.815409           0.803859    0.011551\n",
       "61          3                7        0.815409           0.803859    0.011551\n",
       "88          3               10        0.815409           0.803859    0.011551\n",
       "85          6               10        0.825040           0.813505    0.011535\n",
       "59          5                7        0.828250           0.816720    0.011530\n",
       "31          6                4        0.837881           0.826367    0.011515\n",
       "5           5                1        0.841091           0.829582    0.011509\n",
       "8           2                1        0.807384           0.797428    0.009956\n",
       "26          2                3        0.807384           0.797428    0.009956\n",
       "17          2                2        0.807384           0.797428    0.009956\n",
       "35          2                4        0.807384           0.797428    0.009956\n",
       "68          5                8        0.823435           0.813505    0.009930\n",
       "84          7               10        0.823435           0.813505    0.009930\n",
       "77          5                9        0.823435           0.813505    0.009930\n",
       "55          9                7        0.826645           0.816720    0.009925\n",
       "65          8                8        0.826645           0.816720    0.009925\n",
       "53          2                6        0.802568           0.794212    0.008356\n",
       "86          5               10        0.821830           0.813505    0.008325\n",
       "60          4                7        0.825040           0.816720    0.008320\n",
       "74          8                9        0.825040           0.816720    0.008320\n",
       "48          7                6        0.828250           0.819936    0.008315\n",
       "24          4                3        0.828250           0.819936    0.008315\n",
       "58          6                7        0.828250           0.819936    0.008315\n",
       "40          6                5        0.831461           0.823151    0.008310\n",
       "32          5                4        0.831461           0.823151    0.008310\n",
       "14          5                2        0.837881           0.829582    0.008299\n",
       "89          2               10        0.800963           0.794212    0.006751\n",
       "62          2                7        0.800963           0.794212    0.006751\n",
       "71          2                8        0.800963           0.794212    0.006751\n",
       "80          2                9        0.800963           0.794212    0.006751\n",
       "69          4                8        0.823435           0.816720    0.006715\n",
       "76          6                9        0.823435           0.816720    0.006715\n",
       "56          8                7        0.826645           0.819936    0.006710\n",
       "51          4                6        0.826645           0.819936    0.006710\n",
       "54         10                7        0.826645           0.819936    0.006710\n",
       "66          7                8        0.826645           0.819936    0.006710\n",
       "50          5                6        0.829856           0.823151    0.006704\n",
       "23          5                3        0.833066           0.826367    0.006699\n",
       "45         10                6        0.836276           0.829582    0.006694\n",
       "46          9                6        0.836276           0.829582    0.006694\n",
       "47          8                6        0.839486           0.832797    0.006689\n",
       "38          8                5        0.845907           0.839228    0.006679\n",
       "83          8               10        0.825040           0.819936    0.005104\n",
       "73          9                9        0.825040           0.819936    0.005104\n",
       "64          9                8        0.828250           0.823151    0.005099\n",
       "6           4                1        0.828250           0.823151    0.005099\n",
       "41          5                5        0.828250           0.823151    0.005099\n",
       "82          9               10        0.828250           0.823151    0.005099\n",
       "72         10                9        0.828250           0.823151    0.005099\n",
       "33          4                4        0.828250           0.823151    0.005099\n",
       "49          6                6        0.828250           0.823151    0.005099\n",
       "37          9                5        0.850722           0.845659    0.005063\n",
       "19          9                3        0.869984           0.864952    0.005032\n",
       "0          10                1        0.927769           0.922830    0.004939\n",
       "75          7                9        0.826645           0.823151    0.003494\n",
       "81         10               10        0.826645           0.823151    0.003494\n",
       "78          4                9        0.826645           0.823151    0.003494\n",
       "63         10                8        0.826645           0.823151    0.003494\n",
       "42          4                5        0.829856           0.826367    0.003489\n",
       "30          7                4        0.855538           0.852090    0.003448\n",
       "10          9                2        0.887640           0.884244    0.003396\n",
       "1           9                1        0.922953           0.919614    0.003339\n",
       "57          7                7        0.825040           0.823151    0.001889\n",
       "15          4                2        0.828250           0.826367    0.001884\n",
       "39          7                5        0.847512           0.845659    0.001853\n",
       "28          9                4        0.863563           0.861736    0.001827\n",
       "21          7                3        0.869984           0.868167    0.001817\n",
       "2           8                1        0.908507           0.906752    0.001755\n",
       "36         10                5        0.852327           0.852090    0.000237\n",
       "9          10                2        0.887640           0.887460    0.000181\n",
       "87          4               10        0.821830           0.823151   -0.001321\n",
       "29          8                4        0.857143           0.858521   -0.001378\n",
       "3           7                1        0.895666           0.897106   -0.001440\n",
       "22          6                3        0.839486           0.842444   -0.002957\n",
       "4           6                1        0.861958           0.864952   -0.002994\n",
       "27         10                4        0.865169           0.868167   -0.002999\n",
       "20          8                3        0.871589           0.874598   -0.003009\n",
       "11          8                2        0.884430           0.887460   -0.003030\n",
       "13          6                2        0.853933           0.858521   -0.004588\n",
       "18         10                3        0.869984           0.874598   -0.004614\n",
       "12          7                2        0.876404           0.881029   -0.004624"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df[models_df.difference <= 0.10].sort_values('difference', ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9da6c",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "\n",
    "- The model with the best performance(or closest metrics) on both the train and validate is with a max depth of 10 and min sample leaf of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33b87e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.008320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.006704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>0.922830</td>\n",
       "      <td>0.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855538</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871589</td>\n",
       "      <td>0.874598</td>\n",
       "      <td>-0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.757624</td>\n",
       "      <td>0.762058</td>\n",
       "      <td>-0.004433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_sample_leaf  train_accuracy  validate_accuracy  difference\n",
       "7          3                8        0.815409           0.803859    0.011551\n",
       "6          4                7        0.825040           0.816720    0.008320\n",
       "4          6                5        0.831461           0.823151    0.008310\n",
       "8          2                9        0.800963           0.794212    0.006751\n",
       "5          5                6        0.829856           0.823151    0.006704\n",
       "0         10                1        0.927769           0.922830    0.004939\n",
       "3          7                4        0.855538           0.852090    0.003448\n",
       "1          9                2        0.887640           0.884244    0.003396\n",
       "2          8                3        0.871589           0.874598   -0.003009\n",
       "9          1               10        0.757624           0.762058   -0.004433"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "df\n",
    "df['difference'] = df['train_accuracy'] - df['validate_accuracy'] \n",
    "\n",
    "df.sort_values('difference', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "122d1ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>0.922830</td>\n",
       "      <td>0.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871589</td>\n",
       "      <td>0.874598</td>\n",
       "      <td>-0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855538</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.006704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.008320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>0.803859</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.757624</td>\n",
       "      <td>0.762058</td>\n",
       "      <td>-0.004433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_sample_leaf  train_accuracy  validate_accuracy  difference\n",
       "0         10                1        0.927769           0.922830    0.004939\n",
       "1          9                2        0.887640           0.884244    0.003396\n",
       "2          8                3        0.871589           0.874598   -0.003009\n",
       "3          7                4        0.855538           0.852090    0.003448\n",
       "5          5                6        0.829856           0.823151    0.006704\n",
       "4          6                5        0.831461           0.823151    0.008310\n",
       "6          4                7        0.825040           0.816720    0.008320\n",
       "7          3                8        0.815409           0.803859    0.011551\n",
       "8          2                9        0.800963           0.794212    0.006751\n",
       "9          1               10        0.757624           0.762058   -0.004433"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d01b3b",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "\n",
    "- The model with the best performance(or closest metrics) on both the train and validate is with a max depth of 9 and min sample leaf of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6cdc4284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.max_depth, df.train_accuracy, marker = 'o', label = 'Train')\n",
    "plt.plot(df.max_depth, df.validate_accuracy, marker = 'o', label = 'Validate')\n",
    "plt.title('Overfitting Occurs at Higher Values for Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa737ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
